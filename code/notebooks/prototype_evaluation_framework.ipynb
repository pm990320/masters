{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# add the parent dir of notebooks to path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalutation.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NullPredictor on dataset NAB Tweets with contamination 0%\n",
      "Training NullPredictor on dataset NAB Tweets with contamination 1%\n",
      "Training NullPredictor on dataset NAB Tweets with contamination 2%\n",
      "Training NullPredictor on dataset NAB Tweets with contamination 3%\n",
      "Training NullPredictor on dataset NAB Tweets with contamination 4%\n",
      "Training NullPredictor on dataset NAB Tweets with contamination 5%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 0%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 1%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 2%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 3%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 4%\n",
      "Training NullPredictor on dataset Yahoo A1 with contamination 5%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>contamination</th>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NAB Tweets</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">NullPredictor</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.00</th>\n",
       "      <th>0.50</th>\n",
       "      <td>0.449336</td>\n",
       "      <td>0.515484</td>\n",
       "      <td>0.480142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.413054</td>\n",
       "      <td>0.435241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.449213</td>\n",
       "      <td>0.299190</td>\n",
       "      <td>0.359165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.207718</td>\n",
       "      <td>0.283117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.104812</td>\n",
       "      <td>0.169950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Yahoo A1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">NullPredictor</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.05</th>\n",
       "      <th>0.60</th>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.418231</td>\n",
       "      <td>0.561151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.834586</td>\n",
       "      <td>0.297587</td>\n",
       "      <td>0.438735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.198391</td>\n",
       "      <td>0.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.128686</td>\n",
       "      <td>0.227488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.071979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  precision    recall  \\\n",
       "dataset    model         contamination threshold                        \n",
       "NAB Tweets NullPredictor 0.00          0.50        0.449336  0.515484   \n",
       "                                       0.60        0.459947  0.413054   \n",
       "                                       0.70        0.449213  0.299190   \n",
       "                                       0.80        0.444444  0.207718   \n",
       "                                       0.90        0.448980  0.104812   \n",
       "...                                                     ...       ...   \n",
       "Yahoo A1   NullPredictor 0.05          0.60        0.852459  0.418231   \n",
       "                                       0.70        0.834586  0.297587   \n",
       "                                       0.80        0.813187  0.198391   \n",
       "                                       0.90        0.979592  0.128686   \n",
       "                                       0.95        0.875000  0.037534   \n",
       "\n",
       "                                                        f1  \n",
       "dataset    model         contamination threshold            \n",
       "NAB Tweets NullPredictor 0.00          0.50       0.480142  \n",
       "                                       0.60       0.435241  \n",
       "                                       0.70       0.359165  \n",
       "                                       0.80       0.283117  \n",
       "                                       0.90       0.169950  \n",
       "...                                                    ...  \n",
       "Yahoo A1   NullPredictor 0.05          0.60       0.561151  \n",
       "                                       0.70       0.438735  \n",
       "                                       0.80       0.318966  \n",
       "                                       0.90       0.227488  \n",
       "                                       0.95       0.071979  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_df = evaluate()\n",
    "resulting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.nab.real_tweets import nab_multivariate_tweet_volume, STOCK_NAMES\n",
    "tweet_df = nab_multivariate_tweet_volume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation framework\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(df, frac_cv=0.3):\n",
    "    \"\"\"\n",
    "    :return: (train_df, cv_df)\n",
    "    \"\"\"\n",
    "    split_iloc = len(df) - int(np.floor(len(df) * frac_cv))\n",
    "    return df.iloc[:split_iloc], df.iloc[split_iloc:]\n",
    "\n",
    "train_df, cv_df = cross_validation_split(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate(df, contamination_factor=0.05):\n",
    "    num_indices_to_contaminate = int(np.floor(len(df)*contamination_factor))\n",
    "    contaminated_indices = np.random.randint(0, len(df), size=(num_indices_to_contaminate,))\n",
    "    \n",
    "    contaminated_df = df.copy()\n",
    "    \n",
    "    for index in contaminated_indices:\n",
    "        index = int(index)\n",
    "        for colidx, col in enumerate(df.columns):\n",
    "            if \"anomaly\" in col:\n",
    "                contaminated_df.iat[index, colidx] = True\n",
    "            if \"value\" in col:\n",
    "                contaminated_df.iat[index, colidx] = np.random.random_sample() * np.max(df[col]) * 2\n",
    "    return contaminated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = (~(contaminate(train_df) == train_df))\n",
    "comp_df\n",
    "comp_df.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our evaluation framework to produce a table of results\n",
    "\n",
    "* For each dataset (NAB Tweets, Yahoo A1)\n",
    "    * For varying contamination levels from 0% to 5%\n",
    "        * For each model to be tested\n",
    "            * For various anomaly thresholds from 0 to 1 (0.5, 0.6, 0.7, 0.8, 0.9)\n",
    "                * run the model, output the F1-score, Precision and Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from data.nab.real_tweets import nab_multivariate_tweet_volume, STOCK_NAMES\n",
    "from data.yahoo.a1_benchmark import yahoo_a1_benchmark\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "tweet_df = nab_multivariate_tweet_volume()\n",
    "yahoo_df = yahoo_a1_benchmark()\n",
    "\n",
    "DATASETS = [\n",
    "    (\"NAB Tweets\", tweet_df),\n",
    "    (\"Yahoo A1\", yahoo_df),\n",
    "]\n",
    "CONTAMINATIONS = [0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "ANOMALY_THRESHOLDS = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "\n",
    "class Model(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, df):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict_proba(self, df):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def predict(self, df, anomaly_threshold=0.5):\n",
    "        predictions = self.predict_proba(df)\n",
    "        return np.where(predictions > anomaly_threshold, 1, 0)\n",
    "\n",
    "\n",
    "class NullPredictor(Model):\n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, df):\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, df):\n",
    "        return np.random.rand(len(df))\n",
    "\n",
    "MODELS = [\n",
    "    (\"NullPredictor\", NullPredictor())\n",
    "]\n",
    "\n",
    "\n",
    "def remove_anomaly_labels(df):\n",
    "    removed_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if \"anomaly\" in col:\n",
    "            del removed_df[col]\n",
    "    return removed_df\n",
    "\n",
    "\n",
    "def extract_anomaly_labels_to_row(df):\n",
    "    anomaly_cols = []\n",
    "    for col in df.columns:\n",
    "        if \"anomaly\" in col:\n",
    "            anomaly_cols.append(col)\n",
    "    \n",
    "    anomaly_df = df[anomaly_cols]\n",
    "    return np.where(anomaly_df.any(axis=1), 1, 0)\n",
    "\n",
    "\n",
    "def evaluate(models=MODELS):\n",
    "    # dataset, contamination, threshold, model, precision, recall, f1\n",
    "    results = []\n",
    "    \n",
    "    for dataset_name, df in DATASETS:\n",
    "        train_df, cv_df = cross_validation_split(df)\n",
    "        cv_labels = extract_anomaly_labels_to_row(cv_df)\n",
    "        \n",
    "        for contamination_level in CONTAMINATIONS:\n",
    "            contaminated_train_df = contaminate(train_df, contamination_factor=contamination_level)\n",
    "\n",
    "            for model_label, model in models:\n",
    "                model.reset()\n",
    "                model.fit(contaminated_train_df)\n",
    "\n",
    "                for anomaly_threshold in ANOMALY_THRESHOLDS:\n",
    "                    outputs = model.predict(remove_anomaly_labels(cv_df), anomaly_threshold=anomaly_threshold)\n",
    "                    \n",
    "                    precision, recall, f1, support = precision_recall_fscore_support(cv_labels, outputs)\n",
    "                    \n",
    "                    results.append(\n",
    "                        # dataset, contamination, threshold, model, precision, recall, f1\n",
    "                        [dataset_name, contamination_level, anomaly_threshold, model_label, precision[1], recall[1], f1[1]]\n",
    "                    )\n",
    "    \n",
    "    result_df = pd.DataFrame(results, columns=\"dataset, contamination, threshold, model, precision, recall, f1\".split(\", \"))\n",
    "    result_df.set_index([\"dataset\", \"model\", \"contamination\", \"threshold\"], inplace=True)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resulting_df = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_df.loc[\"NAB Tweets\"].loc[\"NullPredictor\"].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rolling [window=2,center=False,axis=0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.rolling(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
